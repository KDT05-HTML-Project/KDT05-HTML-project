{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정리한 데이터로 노아 모델 돌려보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>통합</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-04-01</td>\n",
       "      <td>50.705398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-05-01</td>\n",
       "      <td>52.552364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-06-01</td>\n",
       "      <td>51.247385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-07-01</td>\n",
       "      <td>47.428339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-08-01</td>\n",
       "      <td>42.293200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           날짜         통합\n",
       "0  2001-04-01  50.705398\n",
       "1  2001-05-01  52.552364\n",
       "2  2001-06-01  51.247385\n",
       "3  2001-07-01  47.428339\n",
       "4  2001-08-01  42.293200"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = '../DATA/SMP_201004_202403.csv'\n",
    "df = pd.read_csv(file, encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 276 entries, 0 to 275\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   날짜      276 non-null    object \n",
      " 1   통합      276 non-null    float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 4.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 276 entries, 0 to 275\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   날짜      276 non-null    datetime64[ns]\n",
      " 1   통합      276 non-null    float64       \n",
      " 2   std     276 non-null    float64       \n",
      " 3   norm    276 non-null    float64       \n",
      " 4   denorm  5 non-null      float64       \n",
      "dtypes: datetime64[ns](1), float64(4)\n",
      "memory usage: 10.9 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>통합</th>\n",
       "      <th>std</th>\n",
       "      <th>norm</th>\n",
       "      <th>denorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-04-01</td>\n",
       "      <td>50.705398</td>\n",
       "      <td>-1.165759</td>\n",
       "      <td>-1.165759</td>\n",
       "      <td>50.705398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-05-01</td>\n",
       "      <td>52.552364</td>\n",
       "      <td>-1.123687</td>\n",
       "      <td>-1.123687</td>\n",
       "      <td>52.552364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-06-01</td>\n",
       "      <td>51.247385</td>\n",
       "      <td>-1.153413</td>\n",
       "      <td>-1.153413</td>\n",
       "      <td>51.247385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-07-01</td>\n",
       "      <td>47.428339</td>\n",
       "      <td>-1.240408</td>\n",
       "      <td>-1.240408</td>\n",
       "      <td>47.428339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-08-01</td>\n",
       "      <td>42.293200</td>\n",
       "      <td>-1.357382</td>\n",
       "      <td>-1.357382</td>\n",
       "      <td>42.293200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          날짜         통합       std      norm     denorm\n",
       "0 2001-04-01  50.705398 -1.165759 -1.165759  50.705398\n",
       "1 2001-05-01  52.552364 -1.123687 -1.123687  52.552364\n",
       "2 2001-06-01  51.247385 -1.153413 -1.153413  51.247385\n",
       "3 2001-07-01  47.428339 -1.240408 -1.240408  47.428339\n",
       "4 2001-08-01  42.293200 -1.357382 -1.357382  42.293200"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 날짜 데이터를 datetime 형식으로 변환\n",
    "df['날짜'] = pd.to_datetime(df['날짜'])\n",
    "df.info()\n",
    "\n",
    "# 통합 열 정규화\n",
    "def normalize(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "def denormalize(x, mean, std):\n",
    "    return x * std + mean\n",
    "\n",
    "df['norm'] = normalize(df['통합'])\n",
    "df['denorm'] = denormalize(df['norm'], df['통합'].mean(), df['통합'].std())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize, denormalize 함수 잘 돌아간다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 이제 std 열을 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n",
      "(tensor([-1.1658, -1.1237, -1.1534, -1.2404, -1.3574, -1.3062, -1.2517, -1.2470,\n",
      "        -1.0387, -0.9969, -1.1334, -1.1704]), tensor(-1.2558))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# dataset 생성\n",
    "class SMPDataset:\n",
    "    def __init__(self, df, seq_len=12):\n",
    "        data = df['std'].values\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx:idx+self.seq_len]\n",
    "        y = self.data[idx+self.seq_len]\n",
    "        return X, y\n",
    "\n",
    "# Check\n",
    "smp_data = SMPDataset(df)\n",
    "print(len(smp_data))\n",
    "for i in range(5):\n",
    "    print(smp_data[i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1658, -1.1237, -1.1534, -1.2404, -1.3574, -1.3062, -1.2517, -1.2470,\n",
      "         -1.0387, -0.9969, -1.1334, -1.1704],\n",
      "        [-1.1237, -1.1534, -1.2404, -1.3574, -1.3062, -1.2517, -1.2470, -1.0387,\n",
      "         -0.9969, -1.1334, -1.1704, -1.2558],\n",
      "        [-1.1534, -1.2404, -1.3574, -1.3062, -1.2517, -1.2470, -1.0387, -0.9969,\n",
      "         -1.1334, -1.1704, -1.2558, -1.2220],\n",
      "        [-1.2404, -1.3574, -1.3062, -1.2517, -1.2470, -1.0387, -0.9969, -1.1334,\n",
      "         -1.1704, -1.2558, -1.2220, -1.4278],\n",
      "        [-1.3574, -1.3062, -1.2517, -1.2470, -1.0387, -0.9969, -1.1334, -1.1704,\n",
      "         -1.2558, -1.2220, -1.4278, -1.4082],\n",
      "        [-1.3062, -1.2517, -1.2470, -1.0387, -0.9969, -1.1334, -1.1704, -1.2558,\n",
      "         -1.2220, -1.4278, -1.4082, -1.4989],\n",
      "        [-1.2517, -1.2470, -1.0387, -0.9969, -1.1334, -1.1704, -1.2558, -1.2220,\n",
      "         -1.4278, -1.4082, -1.4989, -1.3924],\n",
      "        [-1.2470, -1.0387, -0.9969, -1.1334, -1.1704, -1.2558, -1.2220, -1.4278,\n",
      "         -1.4082, -1.4989, -1.3924, -1.2658]])\n",
      "tensor([-1.2558, -1.2220, -1.4278, -1.4082, -1.4989, -1.3924, -1.2658, -1.0919])\n"
     ]
    }
   ],
   "source": [
    "# DataLoader 생성\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "smp_loader = DataLoader(smp_data, batch_size=8, shuffle=False)\n",
    "for X, y in smp_loader:\n",
    "    print(X)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터로더도 순서대로 잘 나오는 걸 확인\n",
    "\n",
    "3. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss: 0.6216112375259399, R-squared: -14.831917199874018\n",
      "Epoch 100: Loss: 0.1586100310087204, R-squared: -1.0979740424861735\n",
      "Epoch 200: Loss: 0.02772047184407711, R-squared: 0.4060756905939087\n",
      "Epoch 300: Loss: 0.03176416829228401, R-squared: 0.32827124319178425\n",
      "Epoch 400: Loss: 0.10248227417469025, R-squared: -0.97089315155095\n",
      "Epoch 500: Loss: 0.03145160898566246, R-squared: 0.16520529347144908\n",
      "Epoch 600: Loss: 0.04853111878037453, R-squared: -0.02910507468186241\n",
      "Epoch 700: Loss: 0.026227988302707672, R-squared: 0.4032188458094159\n",
      "Epoch 800: Loss: 0.11633989214897156, R-squared: -1.367888062502101\n",
      "Epoch 900: Loss: 2.404585361480713, R-squared: -43.426763852536055\n",
      "Epoch 1000: Loss: 0.220439612865448, R-squared: -3.2042815759212138\n",
      "Epoch 1100: Loss: 0.25782281160354614, R-squared: -3.5516567709861677\n",
      "Epoch 1200: Loss: 0.34328746795654297, R-squared: -4.781226739842831\n",
      "Epoch 1300: Loss: 0.2655453681945801, R-squared: -3.2230384455771537\n",
      "Epoch 1400: Loss: 0.04451650753617287, R-squared: 0.25028046016966066\n",
      "Epoch 1500: Loss: 0.034205082803964615, R-squared: 0.31409497892587324\n",
      "Epoch 1600: Loss: 0.024483393877744675, R-squared: 0.4779442012770758\n",
      "Epoch 1700: Loss: 0.02592838555574417, R-squared: 0.36017378895322383\n",
      "Epoch 1800: Loss: 0.026389749720692635, R-squared: 0.4141890006713347\n",
      "Epoch 1900: Loss: 0.0785861536860466, R-squared: -0.5122322794520244\n",
      "Epoch 2000: Loss: 0.07414781302213669, R-squared: -0.4789667929398569\n",
      "Epoch 2100: Loss: 0.041954852640628815, R-squared: 0.07738474651607397\n",
      "Epoch 2200: Loss: 0.049466561526060104, R-squared: 0.031420108804724234\n",
      "Epoch 2300: Loss: 0.40127307176589966, R-squared: -3.872676720388333\n",
      "Epoch 2400: Loss: 0.04680713266134262, R-squared: 0.013530791501054407\n",
      "Epoch 2500: Loss: 0.03836868330836296, R-squared: 0.20210678540263272\n",
      "Epoch 2600: Loss: 0.02803155593574047, R-squared: 0.3325589209234634\n",
      "Epoch 2700: Loss: 0.01807374320924282, R-squared: 0.5960612925084756\n",
      "Epoch 2800: Loss: 1.0790153741836548, R-squared: -16.114669390418715\n",
      "Epoch 2900: Loss: 0.21386651694774628, R-squared: -2.456554098416062\n",
      "Epoch 3000: Loss: 0.27589353919029236, R-squared: -4.0944091854793605\n",
      "Epoch 3100: Loss: 0.023715265095233917, R-squared: 0.4150447534045043\n",
      "Epoch 3200: Loss: 0.16798143088817596, R-squared: -1.6385841097347043\n",
      "Epoch 3300: Loss: 0.05980269983410835, R-squared: -0.22292629756406912\n",
      "Epoch 3400: Loss: 1.2478713989257812, R-squared: -20.796099377294\n",
      "Epoch 3500: Loss: 0.09034694731235504, R-squared: -1.2691688522813802\n",
      "Epoch 3600: Loss: 0.023942675441503525, R-squared: 0.43158753470999767\n",
      "Epoch 3700: Loss: 0.1867697685956955, R-squared: -2.263951010464008\n",
      "Epoch 3800: Loss: 0.05770273506641388, R-squared: -0.40395718737904773\n",
      "Epoch 3900: Loss: 0.027536476030945778, R-squared: 0.343809717779639\n",
      "Epoch 4000: Loss: 0.21864406764507294, R-squared: -2.744693296188941\n",
      "Epoch 4100: Loss: 0.024963002651929855, R-squared: 0.4531843241559961\n",
      "Epoch 4200: Loss: 0.040001701563596725, R-squared: 0.12196820047679491\n",
      "Epoch 4300: Loss: 0.045909371227025986, R-squared: 0.016062947266496375\n",
      "Epoch 4400: Loss: 0.041327934712171555, R-squared: 0.036435102674429176\n",
      "Epoch 4500: Loss: 0.051774900406599045, R-squared: -0.07928329513010235\n",
      "Epoch 4600: Loss: 0.03521896153688431, R-squared: 0.17614080451225822\n",
      "Epoch 4700: Loss: 0.02609587460756302, R-squared: 0.39073017976425894\n",
      "Epoch 4800: Loss: 0.16160443425178528, R-squared: -1.9277076583891661\n",
      "Epoch 4900: Loss: 0.039554573595523834, R-squared: 0.1257340592345595\n",
      "Epoch 5000: Loss: 0.03163983300328255, R-squared: 0.2572400618430841\n",
      "Epoch 5100: Loss: 0.04630597308278084, R-squared: 0.013649914065397617\n",
      "Epoch 5200: Loss: 0.05277947708964348, R-squared: 0.10909922988795773\n",
      "Epoch 5300: Loss: 0.033139459788799286, R-squared: 0.2539210253903692\n",
      "Epoch 5400: Loss: 0.10203622281551361, R-squared: -1.1337282980516634\n",
      "Epoch 5500: Loss: 0.08640445023775101, R-squared: -0.810941504129858\n",
      "Epoch 5600: Loss: 0.06314931809902191, R-squared: 0.13183911345893784\n",
      "Epoch 5700: Loss: 0.07756340503692627, R-squared: -0.5355947445929983\n",
      "Epoch 5800: Loss: 0.12929441034793854, R-squared: -1.2961576503188756\n",
      "Epoch 5900: Loss: 0.08765815198421478, R-squared: -0.4761557128711116\n",
      "Epoch 6000: Loss: 0.04585457965731621, R-squared: -0.00015835391010665667\n",
      "Epoch 6100: Loss: 0.05714179947972298, R-squared: -0.2528214343856987\n",
      "Epoch 6200: Loss: 0.04554041475057602, R-squared: 0.1062482754341112\n",
      "Epoch 6300: Loss: 0.07426825910806656, R-squared: -0.3911095667325719\n",
      "Epoch 6400: Loss: 0.05232279375195503, R-squared: -0.014650443644942612\n",
      "Epoch 6500: Loss: 0.07101604342460632, R-squared: -0.21516627981886915\n",
      "Epoch 6600: Loss: 0.04069126024842262, R-squared: 0.15815532892693085\n",
      "Epoch 6700: Loss: 0.22799383103847504, R-squared: -3.1954319524538137\n",
      "Epoch 6800: Loss: 0.035080526024103165, R-squared: 0.09547419685318048\n",
      "Epoch 6900: Loss: 0.023180006071925163, R-squared: 0.4416306488966417\n",
      "Epoch 7000: Loss: 0.029174499213695526, R-squared: 0.33830576123331335\n",
      "Epoch 7100: Loss: 0.1089637279510498, R-squared: -1.314535729347496\n",
      "Epoch 7200: Loss: 0.15661264955997467, R-squared: -2.2226130958844696\n",
      "Epoch 7300: Loss: 0.040510423481464386, R-squared: 0.21299634306693038\n",
      "Epoch 7400: Loss: 0.031406231224536896, R-squared: 0.3738739971980062\n",
      "Epoch 7500: Loss: 0.042434483766555786, R-squared: 0.1750855668056418\n",
      "Epoch 7600: Loss: 0.03416483476758003, R-squared: 0.20450396760501766\n",
      "Epoch 7700: Loss: 0.03905574232339859, R-squared: 0.14938439940682635\n",
      "Epoch 7800: Loss: 0.0566771999001503, R-squared: -0.15839198055140913\n",
      "Epoch 7900: Loss: 0.3431304395198822, R-squared: -4.054286443661595\n",
      "Epoch 8000: Loss: 0.5533537864685059, R-squared: -8.702892972372934\n",
      "Epoch 8100: Loss: 0.16872626543045044, R-squared: -1.6999915367715994\n",
      "Epoch 8200: Loss: 0.44503864645957947, R-squared: -6.719929813411736\n",
      "Epoch 8300: Loss: 0.06417272984981537, R-squared: -0.3089830100872233\n",
      "Epoch 8400: Loss: 0.031564436852931976, R-squared: 0.3429330842006454\n",
      "Epoch 8500: Loss: 0.07973416149616241, R-squared: -0.5736360645149583\n",
      "Epoch 8600: Loss: 0.04516153782606125, R-squared: -0.0010326904083379773\n",
      "Epoch 8700: Loss: 0.35564887523651123, R-squared: -5.383678165242973\n",
      "Epoch 8800: Loss: 0.020757054910063744, R-squared: 0.5432455394842712\n",
      "Epoch 8900: Loss: 0.11742208898067474, R-squared: -0.7363703089139206\n",
      "Epoch 9000: Loss: 0.033757928758859634, R-squared: 0.23210878763630216\n",
      "Epoch 9100: Loss: 0.34899526834487915, R-squared: -6.86417878775522\n",
      "Epoch 9200: Loss: 0.029577482491731644, R-squared: 0.2767260888844366\n",
      "Epoch 9300: Loss: 0.03497225046157837, R-squared: 0.16831094092742405\n",
      "Epoch 9400: Loss: 0.03440741077065468, R-squared: 0.28663287213554156\n",
      "Epoch 9500: Loss: 0.029947876930236816, R-squared: 0.29231203237285086\n",
      "Epoch 9600: Loss: 0.030342401936650276, R-squared: 0.39412857616766517\n",
      "Epoch 9700: Loss: 0.04584602266550064, R-squared: -0.06804480564776694\n",
      "Epoch 9800: Loss: 0.026611559092998505, R-squared: 0.46485599744509487\n",
      "Epoch 9900: Loss: 0.3973013162612915, R-squared: -5.44058510412274\n",
      "Epoch 10000: Loss: 0.023147540166974068, R-squared: 0.4616242399096424\n",
      "Epoch 10100: Loss: 0.10876063257455826, R-squared: -1.5562375824136998\n",
      "Epoch 10200: Loss: 0.08915582299232483, R-squared: -0.767928526483759\n",
      "Epoch 10300: Loss: 0.02813839726150036, R-squared: 0.3734140066982423\n",
      "Epoch 10400: Loss: 0.09250548481941223, R-squared: -0.6716420762861759\n",
      "Epoch 10500: Loss: 0.12312424927949905, R-squared: -1.5275277693415217\n",
      "Epoch 10600: Loss: 0.05548859015107155, R-squared: -0.09943495529551849\n",
      "Epoch 10700: Loss: 0.09012105315923691, R-squared: -0.8417964201325678\n",
      "Epoch 10800: Loss: 0.04470352455973625, R-squared: -0.04238782304546329\n",
      "Epoch 10900: Loss: 0.01939019374549389, R-squared: 0.5457931716679184\n",
      "Epoch 11000: Loss: 0.02783321775496006, R-squared: 0.3638255761028809\n",
      "Epoch 11100: Loss: 0.025176331400871277, R-squared: 0.5105059970939321\n",
      "Epoch 11200: Loss: 0.0711212158203125, R-squared: -0.2188557277565637\n",
      "Epoch 11300: Loss: 0.029138892889022827, R-squared: 0.4265181886471535\n",
      "Epoch 11400: Loss: 0.27254921197891235, R-squared: -3.5252429458721855\n",
      "Epoch 11500: Loss: 0.0631948783993721, R-squared: -0.5191799251481155\n",
      "Epoch 11600: Loss: 0.026897886767983437, R-squared: 0.3745567816016053\n",
      "Epoch 11700: Loss: 0.030765902251005173, R-squared: 0.38128481630166877\n",
      "Epoch 11800: Loss: 0.036983516067266464, R-squared: 0.1036609069631571\n",
      "Epoch 11900: Loss: 0.18072964251041412, R-squared: -2.005295392268145\n",
      "Epoch 12000: Loss: 0.037797991186380386, R-squared: 0.18990438504998597\n",
      "Epoch 12100: Loss: 0.02351801097393036, R-squared: 0.43804303831618707\n",
      "Epoch 12200: Loss: 0.022965017706155777, R-squared: 0.43592294037403334\n",
      "Epoch 12300: Loss: 0.02978133037686348, R-squared: 0.2690554119049321\n",
      "Epoch 12400: Loss: 0.025897864252328873, R-squared: 0.38681449978888227\n",
      "Epoch 12500: Loss: 0.03211205080151558, R-squared: 0.24429830310087808\n",
      "Epoch 12600: Loss: 0.2155464142560959, R-squared: -2.300568068184163\n",
      "Epoch 12700: Loss: 0.026197291910648346, R-squared: 0.38035338799140184\n",
      "Epoch 12800: Loss: 0.021069256588816643, R-squared: 0.4641821945123521\n",
      "Epoch 12900: Loss: 0.032083943486213684, R-squared: 0.25183755822329235\n",
      "Epoch 13000: Loss: 0.12801869213581085, R-squared: -1.4834984240574922\n",
      "Epoch 13100: Loss: 0.07128226011991501, R-squared: -0.3910408461646848\n",
      "Epoch 13200: Loss: 0.10090813785791397, R-squared: -1.2491731040424008\n",
      "Epoch 13300: Loss: 0.08747018873691559, R-squared: -0.5854006047690758\n",
      "Epoch 13400: Loss: 0.030788082629442215, R-squared: 0.23751381535278182\n",
      "Epoch 13500: Loss: 0.029614286497235298, R-squared: 0.2685892778796768\n",
      "Epoch 13600: Loss: 0.17836374044418335, R-squared: -1.9266112100777741\n",
      "Epoch 13700: Loss: 0.019219260662794113, R-squared: 0.5461107210302405\n",
      "Epoch 13800: Loss: 0.29199984669685364, R-squared: -3.3040184144409777\n",
      "Epoch 13900: Loss: 0.026402117684483528, R-squared: 0.40914013866171983\n",
      "Epoch 14000: Loss: 0.023512477055191994, R-squared: 0.43192366221064726\n",
      "Epoch 14100: Loss: 0.27740827202796936, R-squared: -4.199313140314224\n",
      "Epoch 14200: Loss: 0.12172197550535202, R-squared: -1.1558135347554828\n",
      "Epoch 14300: Loss: 0.037803370505571365, R-squared: 0.2268890401661181\n",
      "Epoch 14400: Loss: 0.13303279876708984, R-squared: -1.4234143365684653\n",
      "Epoch 14500: Loss: 0.037325166165828705, R-squared: 0.37009911860725986\n",
      "Epoch 14600: Loss: 0.05534789711236954, R-squared: -0.02155421064237295\n",
      "Epoch 14700: Loss: 0.02224097214639187, R-squared: 0.46621434131819106\n",
      "Epoch 14800: Loss: 0.11016051471233368, R-squared: -1.0587235003044695\n",
      "Epoch 14900: Loss: 0.07714982330799103, R-squared: -0.3162514003122714\n",
      "Epoch 15000: Loss: 0.11318982392549515, R-squared: -1.0633401206720183\n",
      "Epoch 15100: Loss: 0.07909397780895233, R-squared: -0.39191948538363786\n",
      "Epoch 15200: Loss: 0.16097109019756317, R-squared: -0.8834782597469104\n",
      "Epoch 15300: Loss: 0.03959004208445549, R-squared: 0.19695370537849366\n",
      "Epoch 15400: Loss: 0.056972935795784, R-squared: -0.1398786559981855\n",
      "Epoch 15500: Loss: 0.033114299178123474, R-squared: 0.2847930317460181\n",
      "Epoch 15600: Loss: 0.025045311078429222, R-squared: 0.4691281797813093\n",
      "Epoch 15700: Loss: 0.029141612350940704, R-squared: 0.27215072568623266\n",
      "Epoch 15800: Loss: 0.09388287365436554, R-squared: -1.0528947066585213\n",
      "Epoch 15900: Loss: 2.3638477325439453, R-squared: -36.165397279103075\n",
      "Epoch 16000: Loss: 1.0396554470062256, R-squared: -13.130349565219362\n",
      "Epoch 16100: Loss: 0.0858694463968277, R-squared: -0.6663802985208196\n",
      "Epoch 16200: Loss: 0.12258946895599365, R-squared: -1.3320460279186115\n",
      "Epoch 16300: Loss: 0.29958227276802063, R-squared: -5.307495301017087\n",
      "Epoch 16400: Loss: 0.023911070078611374, R-squared: 0.43400793804278603\n",
      "Epoch 16500: Loss: 0.12154097110033035, R-squared: -0.7383752133847485\n",
      "Epoch 16600: Loss: 0.15709319710731506, R-squared: -1.7071558100824689\n",
      "Epoch 16700: Loss: 0.0255512073636055, R-squared: 0.4004546805160991\n",
      "Epoch 16800: Loss: 0.1421467363834381, R-squared: -1.6229970666060778\n",
      "Epoch 16900: Loss: 0.026023611426353455, R-squared: 0.3945713940823713\n",
      "Epoch 17000: Loss: 0.030297724530100822, R-squared: 0.31737231146795086\n",
      "Epoch 17100: Loss: 0.10235951095819473, R-squared: -0.7979083032650658\n",
      "Epoch 17200: Loss: 0.036773327738046646, R-squared: 0.25557128631439807\n",
      "Epoch 17300: Loss: 0.020787058398127556, R-squared: 0.5154388375344849\n",
      "Epoch 17400: Loss: 0.03363702446222305, R-squared: 0.18669421045446755\n",
      "Epoch 17500: Loss: 0.075415700674057, R-squared: -0.7222900428281278\n",
      "Epoch 17600: Loss: 0.06363215297460556, R-squared: -0.24894047328594926\n",
      "Epoch 17700: Loss: 0.07536647468805313, R-squared: -0.5309511474616011\n",
      "Epoch 17800: Loss: 0.052388403564691544, R-squared: -0.2290103969460191\n",
      "Epoch 17900: Loss: 0.03146074712276459, R-squared: 0.10927922667186263\n",
      "Epoch 18000: Loss: 0.04997145012021065, R-squared: -0.05789175007788949\n",
      "Epoch 18100: Loss: 0.09849119186401367, R-squared: -0.6752378889031796\n",
      "Epoch 18200: Loss: 0.6696105599403381, R-squared: -9.142834592064338\n",
      "Epoch 18300: Loss: 0.056249428540468216, R-squared: -0.0262430253130006\n",
      "Epoch 18400: Loss: 0.07205452024936676, R-squared: -0.20834898082318443\n",
      "Epoch 18500: Loss: 2.063951253890991, R-squared: -26.19187361623396\n",
      "Epoch 18600: Loss: 0.08898347616195679, R-squared: -0.6366821390179707\n",
      "Epoch 18700: Loss: 0.03714333474636078, R-squared: 0.23316547889132966\n",
      "Epoch 18800: Loss: 0.04408960044384003, R-squared: -0.0772073082499456\n",
      "Epoch 18900: Loss: 0.035201020538806915, R-squared: 0.2083558113999403\n",
      "Epoch 19000: Loss: 0.027614103630185127, R-squared: 0.40222896012160436\n",
      "Epoch 19100: Loss: 0.1324990838766098, R-squared: -1.6274452427457793\n",
      "Epoch 19200: Loss: 0.041481368243694305, R-squared: 0.20287445387088954\n",
      "Epoch 19300: Loss: 0.09024480730295181, R-squared: -0.835561542775257\n",
      "Epoch 19400: Loss: 0.026508435606956482, R-squared: 0.4515774044560402\n",
      "Epoch 19500: Loss: 0.11108261346817017, R-squared: -1.5816959609253924\n",
      "Epoch 19600: Loss: 0.02698993682861328, R-squared: 0.38524369325274177\n",
      "Epoch 19700: Loss: 0.02767355926334858, R-squared: 0.32545737945706577\n",
      "Epoch 19800: Loss: 0.02015696093440056, R-squared: 0.5022307765504117\n",
      "Epoch 19900: Loss: 0.15528357028961182, R-squared: -2.210330463293842\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=12, hidden_size=30, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(30, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _status = self.rnn(x)\n",
    "        x = self.fc(x[:, -1])\n",
    "        return x\n",
    "\n",
    "model = RNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "def compute_r2_score(y_true, y_pred):\n",
    "    return r2_score(y_true.detach().cpu().numpy(), y_pred.detach().cpu().numpy())\n",
    "\n",
    "for epoch in range(200000):\n",
    "    for i, (x, y) in enumerate(smp_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x.unsqueeze(1).float())\n",
    "        loss = criterion(output.squeeze(), y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        y_true = y.float().unsqueeze(1)  \n",
    "        y_pred = model(x.unsqueeze(1).float())  \n",
    "        r2 = compute_r2_score(y_true, y_pred.squeeze())\n",
    "\n",
    "        print(f\"Epoch {epoch}: Loss: {loss}, R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
