{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정리한 데이터로 노아 모델 돌려보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>통합</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-04-01</td>\n",
       "      <td>50.705398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-05-01</td>\n",
       "      <td>52.552364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-06-01</td>\n",
       "      <td>51.247385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-07-01</td>\n",
       "      <td>47.428339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-08-01</td>\n",
       "      <td>42.293200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           날짜         통합\n",
       "0  2001-04-01  50.705398\n",
       "1  2001-05-01  52.552364\n",
       "2  2001-06-01  51.247385\n",
       "3  2001-07-01  47.428339\n",
       "4  2001-08-01  42.293200"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = '../DATA/SMP_201004_202403.csv'\n",
    "df = pd.read_csv(file, encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 276 entries, 0 to 275\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   날짜      276 non-null    object \n",
      " 1   통합      276 non-null    float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 4.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 276 entries, 0 to 275\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   날짜      276 non-null    datetime64[ns]\n",
      " 1   통합      276 non-null    float64       \n",
      " 2   std     276 non-null    float64       \n",
      " 3   norm    276 non-null    float64       \n",
      " 4   denorm  5 non-null      float64       \n",
      "dtypes: datetime64[ns](1), float64(4)\n",
      "memory usage: 10.9 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>통합</th>\n",
       "      <th>std</th>\n",
       "      <th>norm</th>\n",
       "      <th>denorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-04-01</td>\n",
       "      <td>50.705398</td>\n",
       "      <td>-1.165759</td>\n",
       "      <td>-1.165759</td>\n",
       "      <td>50.705398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-05-01</td>\n",
       "      <td>52.552364</td>\n",
       "      <td>-1.123687</td>\n",
       "      <td>-1.123687</td>\n",
       "      <td>52.552364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-06-01</td>\n",
       "      <td>51.247385</td>\n",
       "      <td>-1.153413</td>\n",
       "      <td>-1.153413</td>\n",
       "      <td>51.247385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-07-01</td>\n",
       "      <td>47.428339</td>\n",
       "      <td>-1.240408</td>\n",
       "      <td>-1.240408</td>\n",
       "      <td>47.428339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-08-01</td>\n",
       "      <td>42.293200</td>\n",
       "      <td>-1.357382</td>\n",
       "      <td>-1.357382</td>\n",
       "      <td>42.293200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          날짜         통합       std      norm     denorm\n",
       "0 2001-04-01  50.705398 -1.165759 -1.165759  50.705398\n",
       "1 2001-05-01  52.552364 -1.123687 -1.123687  52.552364\n",
       "2 2001-06-01  51.247385 -1.153413 -1.153413  51.247385\n",
       "3 2001-07-01  47.428339 -1.240408 -1.240408  47.428339\n",
       "4 2001-08-01  42.293200 -1.357382 -1.357382  42.293200"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 날짜 데이터를 datetime 형식으로 변환\n",
    "df['날짜'] = pd.to_datetime(df['날짜'])\n",
    "df.info()\n",
    "\n",
    "# 통합 열 정규화\n",
    "def normalize(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "def denormalize(x, mean, std):\n",
    "    return x * std + mean\n",
    "\n",
    "df['norm'] = normalize(df['통합'])\n",
    "df['denorm'] = denormalize(df['norm'], df['통합'].mean(), df['통합'].std())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize, denormalize 함수 잘 돌아간다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 이제 std 열을 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n",
      "(tensor([-1.1658, -1.1237, -1.1534, -1.2404, -1.3574, -1.3062, -1.2517, -1.2470,\n",
      "        -1.0387, -0.9969, -1.1334, -1.1704]), tensor(-1.2558))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# dataset 생성\n",
    "class SMPDataset:\n",
    "    def __init__(self, df, seq_len=12):\n",
    "        data = df['std'].values\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx:idx+self.seq_len]\n",
    "        y = self.data[idx+self.seq_len]\n",
    "        return X, y\n",
    "\n",
    "# Check\n",
    "smp_data = SMPDataset(df)\n",
    "print(len(smp_data))\n",
    "for i in range(5):\n",
    "    print(smp_data[i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1658, -1.1237, -1.1534, -1.2404, -1.3574, -1.3062, -1.2517, -1.2470,\n",
      "         -1.0387, -0.9969, -1.1334, -1.1704],\n",
      "        [-1.1237, -1.1534, -1.2404, -1.3574, -1.3062, -1.2517, -1.2470, -1.0387,\n",
      "         -0.9969, -1.1334, -1.1704, -1.2558],\n",
      "        [-1.1534, -1.2404, -1.3574, -1.3062, -1.2517, -1.2470, -1.0387, -0.9969,\n",
      "         -1.1334, -1.1704, -1.2558, -1.2220],\n",
      "        [-1.2404, -1.3574, -1.3062, -1.2517, -1.2470, -1.0387, -0.9969, -1.1334,\n",
      "         -1.1704, -1.2558, -1.2220, -1.4278],\n",
      "        [-1.3574, -1.3062, -1.2517, -1.2470, -1.0387, -0.9969, -1.1334, -1.1704,\n",
      "         -1.2558, -1.2220, -1.4278, -1.4082],\n",
      "        [-1.3062, -1.2517, -1.2470, -1.0387, -0.9969, -1.1334, -1.1704, -1.2558,\n",
      "         -1.2220, -1.4278, -1.4082, -1.4989],\n",
      "        [-1.2517, -1.2470, -1.0387, -0.9969, -1.1334, -1.1704, -1.2558, -1.2220,\n",
      "         -1.4278, -1.4082, -1.4989, -1.3924],\n",
      "        [-1.2470, -1.0387, -0.9969, -1.1334, -1.1704, -1.2558, -1.2220, -1.4278,\n",
      "         -1.4082, -1.4989, -1.3924, -1.2658]])\n",
      "tensor([-1.2558, -1.2220, -1.4278, -1.4082, -1.4989, -1.3924, -1.2658, -1.0919])\n"
     ]
    }
   ],
   "source": [
    "# DataLoader 생성\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "smp_loader = DataLoader(smp_data, batch_size=8, shuffle=False)\n",
    "for X, y in smp_loader:\n",
    "    print(X)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터로더도 순서대로 잘 나오는 걸 확인\n",
    "\n",
    "3. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss: 0.5884777903556824, R-squared: -14.657509517359172\n",
      "Epoch 1000: Loss: 3.158687114715576, R-squared: -51.80693239202994\n",
      "Epoch 2000: Loss: 0.058236263692379, R-squared: -0.8353330845929758\n",
      "Epoch 3000: Loss: 0.10228029638528824, R-squared: -0.939897020225609\n",
      "Epoch 4000: Loss: 0.14891520142555237, R-squared: -1.728776129921088\n",
      "Epoch 5000: Loss: 0.03082852065563202, R-squared: 0.2708598671948067\n",
      "Epoch 6000: Loss: 0.09411229938268661, R-squared: -0.6788758701931552\n",
      "Epoch 7000: Loss: 0.07331418246030807, R-squared: -0.4222568164056417\n",
      "Epoch 8000: Loss: 0.199615478515625, R-squared: -2.9832241359865397\n",
      "Epoch 9000: Loss: 0.08042310178279877, R-squared: -0.20642671227327725\n",
      "Epoch 10000: Loss: 0.15546779334545135, R-squared: -2.813070248656389\n",
      "Epoch 11000: Loss: 0.041518837213516235, R-squared: 0.11616140081449244\n",
      "Epoch 12000: Loss: 0.03944193199276924, R-squared: 0.03473109368330285\n",
      "Epoch 13000: Loss: 0.030518528074026108, R-squared: 0.42493771217665244\n",
      "Epoch 14000: Loss: 0.3650287985801697, R-squared: -5.45430965219423\n",
      "Epoch 15000: Loss: 0.033337999135255814, R-squared: 0.250279691024318\n",
      "Epoch 16000: Loss: 0.06812945008277893, R-squared: -0.347950142041606\n",
      "Epoch 17000: Loss: 0.06177667900919914, R-squared: 0.06923208797982605\n",
      "Epoch 18000: Loss: 0.12295053899288177, R-squared: -1.2526758764129413\n",
      "Epoch 19000: Loss: 0.02996835671365261, R-squared: 0.27396354894466346\n",
      "Epoch 20000: Loss: 0.25623294711112976, R-squared: -3.7185984446425877\n",
      "Epoch 21000: Loss: 0.10364232212305069, R-squared: -0.7802761652224046\n",
      "Epoch 22000: Loss: 0.45432817935943604, R-squared: -4.808276353566565\n",
      "Epoch 23000: Loss: 0.065163753926754, R-squared: -0.3410918853766314\n",
      "Epoch 24000: Loss: 0.021281586959958076, R-squared: 0.51030344519411\n",
      "Epoch 25000: Loss: 0.029502594843506813, R-squared: 0.32199590145073975\n",
      "Epoch 26000: Loss: 0.029276501387357712, R-squared: 0.32192713204684087\n",
      "Epoch 27000: Loss: 0.025042081251740456, R-squared: 0.3923718626636934\n",
      "Epoch 28000: Loss: 0.059458427131175995, R-squared: -0.20282027909596678\n",
      "Epoch 29000: Loss: 0.0326242670416832, R-squared: 0.2994438410058241\n",
      "Epoch 30000: Loss: 0.08973751217126846, R-squared: -0.6142599039119077\n",
      "Epoch 31000: Loss: 0.03961413726210594, R-squared: 0.16121352698992764\n",
      "Epoch 32000: Loss: 0.10336088389158249, R-squared: -0.6666027792126776\n",
      "Epoch 33000: Loss: 0.06660299003124237, R-squared: -0.00010800603786398355\n",
      "Epoch 34000: Loss: 0.03383561596274376, R-squared: 0.23248674324644913\n",
      "Epoch 35000: Loss: 0.02482529729604721, R-squared: 0.4277681043107904\n",
      "Epoch 36000: Loss: 0.09889374673366547, R-squared: -0.8068129546305782\n",
      "Epoch 37000: Loss: 0.08946210145950317, R-squared: -0.49425242920300994\n",
      "Epoch 38000: Loss: 0.03140406310558319, R-squared: 0.22543185408375832\n",
      "Epoch 39000: Loss: 0.2539843022823334, R-squared: -4.358063416704973\n",
      "Epoch 40000: Loss: 1.633431315422058, R-squared: -31.4409747499733\n",
      "Epoch 41000: Loss: 0.03592773154377937, R-squared: 0.07261270694063693\n",
      "Epoch 42000: Loss: 0.06707210093736649, R-squared: -0.2008681551057201\n",
      "Epoch 43000: Loss: 0.02848277986049652, R-squared: 0.4098350046927297\n",
      "Epoch 44000: Loss: 0.027745414525270462, R-squared: 0.3889254803359601\n",
      "Epoch 45000: Loss: 0.15899935364723206, R-squared: -0.8804536528225146\n",
      "Epoch 46000: Loss: 0.036013707518577576, R-squared: 0.26044483902085414\n",
      "Epoch 47000: Loss: 0.13108600676059723, R-squared: -1.0635841506833232\n",
      "Epoch 48000: Loss: 0.6137400269508362, R-squared: -10.333537212470349\n",
      "Epoch 49000: Loss: 0.015940915793180466, R-squared: 0.5907465188959451\n",
      "Epoch 50000: Loss: 0.02359413169324398, R-squared: 0.4426190311953542\n",
      "Epoch 51000: Loss: 0.02125871367752552, R-squared: 0.5005889898635322\n",
      "Epoch 52000: Loss: 0.04876459762454033, R-squared: -0.1148456242961915\n",
      "Epoch 53000: Loss: 0.06501096487045288, R-squared: -0.19320965729460493\n",
      "Epoch 54000: Loss: 0.07059591263532639, R-squared: -0.535099025964149\n",
      "Epoch 55000: Loss: 0.020655477419495583, R-squared: 0.4903289179057727\n",
      "Epoch 56000: Loss: 0.04857639595866203, R-squared: 0.04960362140633012\n",
      "Epoch 57000: Loss: 0.06490734219551086, R-squared: -0.1916166935585777\n",
      "Epoch 58000: Loss: 0.05139057710766792, R-squared: -0.0664636250628825\n",
      "Epoch 59000: Loss: 0.03312719985842705, R-squared: 0.3251812618484622\n",
      "Epoch 60000: Loss: 0.1413651555776596, R-squared: -1.83182415259482\n",
      "Epoch 61000: Loss: 0.034422341734170914, R-squared: 0.2526423860914375\n",
      "Epoch 62000: Loss: 0.05547025054693222, R-squared: -0.0019872060686949578\n",
      "Epoch 63000: Loss: 0.3104931116104126, R-squared: -5.375950351964469\n",
      "Epoch 64000: Loss: 0.021879002451896667, R-squared: 0.4781348362959488\n",
      "Epoch 65000: Loss: 0.04266698658466339, R-squared: 0.055471483643187325\n",
      "Epoch 66000: Loss: 0.1247403472661972, R-squared: -1.788757001669551\n",
      "Epoch 67000: Loss: 0.07619170099496841, R-squared: -0.3242839565273905\n",
      "Epoch 68000: Loss: 0.03559355065226555, R-squared: 0.21264258163816674\n",
      "Epoch 69000: Loss: 0.023114703595638275, R-squared: 0.43022527376843456\n",
      "Epoch 70000: Loss: 0.02909756265580654, R-squared: 0.3520452033273598\n",
      "Epoch 71000: Loss: 0.025145364925265312, R-squared: 0.44988764840015405\n",
      "Epoch 72000: Loss: 1.0400420427322388, R-squared: -20.87548397727006\n",
      "Epoch 73000: Loss: 0.04085996747016907, R-squared: 0.08118377936250998\n",
      "Epoch 74000: Loss: 0.06472271680831909, R-squared: -0.30559260064316374\n",
      "Epoch 75000: Loss: 0.036695025861263275, R-squared: 0.3278878434232284\n",
      "Epoch 76000: Loss: 0.5296251177787781, R-squared: -8.507591575788794\n",
      "Epoch 77000: Loss: 0.042712051421403885, R-squared: 0.12444695537394945\n",
      "Epoch 78000: Loss: 0.08134663105010986, R-squared: -0.4937351711847664\n",
      "Epoch 79000: Loss: 0.056393787264823914, R-squared: -0.32346959738115477\n",
      "Epoch 80000: Loss: 0.9623973369598389, R-squared: -13.880589506831592\n",
      "Epoch 81000: Loss: 0.031059622764587402, R-squared: 0.2839684684505618\n",
      "Epoch 82000: Loss: 0.082783043384552, R-squared: -0.20120374776085703\n",
      "Epoch 83000: Loss: 0.04354740306735039, R-squared: 0.0692162845940395\n",
      "Epoch 84000: Loss: 0.023332636803388596, R-squared: 0.46925988179297284\n",
      "Epoch 85000: Loss: 0.06991901248693466, R-squared: -0.33588888833356\n",
      "Epoch 86000: Loss: 0.027153044939041138, R-squared: 0.3858264088736404\n",
      "Epoch 87000: Loss: 0.04886598512530327, R-squared: -0.038714683321629195\n",
      "Epoch 88000: Loss: 0.05233927071094513, R-squared: -0.2043110712123477\n",
      "Epoch 89000: Loss: 0.1519262194633484, R-squared: -0.7430426401194206\n",
      "Epoch 90000: Loss: 0.053968850523233414, R-squared: -0.17823577593328577\n",
      "Epoch 91000: Loss: 0.028275391086935997, R-squared: 0.20426619956659875\n",
      "Epoch 92000: Loss: 0.2301495522260666, R-squared: -2.790731297209085\n",
      "Epoch 93000: Loss: 0.032950181514024734, R-squared: 0.3776731509386878\n",
      "Epoch 94000: Loss: 0.21150361001491547, R-squared: -2.3745413114517078\n",
      "Epoch 95000: Loss: 0.022829558700323105, R-squared: 0.46230355001104273\n",
      "Epoch 96000: Loss: 0.017345836386084557, R-squared: 0.5975872314830952\n",
      "Epoch 97000: Loss: 0.09049288183450699, R-squared: -0.7255828137963523\n",
      "Epoch 98000: Loss: 0.0505448579788208, R-squared: -0.18978340348476297\n",
      "Epoch 99000: Loss: 0.11207661032676697, R-squared: -1.5863531639312565\n",
      "Epoch 100000: Loss: 0.05105152726173401, R-squared: -0.18839410871264572\n",
      "Epoch 101000: Loss: 0.028041213750839233, R-squared: 0.32848671794887097\n",
      "Epoch 102000: Loss: 0.030642054975032806, R-squared: 0.341643749630711\n",
      "Epoch 103000: Loss: 0.02703866735100746, R-squared: 0.38582161789381586\n",
      "Epoch 104000: Loss: 0.06227477267384529, R-squared: -0.04260937429557843\n",
      "Epoch 105000: Loss: 0.23607893288135529, R-squared: -2.3134544907017918\n",
      "Epoch 106000: Loss: 0.029426775872707367, R-squared: 0.29751351866920606\n",
      "Epoch 107000: Loss: 0.05007930472493172, R-squared: -0.09234253614946608\n",
      "Epoch 108000: Loss: 0.03552636504173279, R-squared: -0.03227693191144421\n",
      "Epoch 109000: Loss: 0.08978275954723358, R-squared: -1.0303784158838782\n",
      "Epoch 110000: Loss: 0.0248580165207386, R-squared: 0.3626327783155351\n",
      "Epoch 111000: Loss: 0.024382680654525757, R-squared: 0.42843431434863377\n",
      "Epoch 112000: Loss: 0.09958545118570328, R-squared: -1.1355108833282772\n",
      "Epoch 113000: Loss: 0.02192099019885063, R-squared: 0.5146577350405758\n",
      "Epoch 114000: Loss: 1.181664228439331, R-squared: -20.81599700026956\n",
      "Epoch 115000: Loss: 0.06715134531259537, R-squared: -0.2844761412439578\n",
      "Epoch 116000: Loss: 0.03810373693704605, R-squared: 0.18563022865559775\n",
      "Epoch 117000: Loss: 0.05106925219297409, R-squared: -0.13064627596503153\n",
      "Epoch 118000: Loss: 0.0353345163166523, R-squared: 0.2114301081990283\n",
      "Epoch 119000: Loss: 0.06475932896137238, R-squared: -0.03564183462986481\n",
      "Epoch 120000: Loss: 0.21550308167934418, R-squared: -3.6496166146858853\n",
      "Epoch 121000: Loss: 0.028080202639102936, R-squared: 0.33139350043825644\n",
      "Epoch 122000: Loss: 0.1755053997039795, R-squared: -2.1240374997937037\n",
      "Epoch 123000: Loss: 0.1286451369524002, R-squared: -1.1937750795235633\n",
      "Epoch 124000: Loss: 0.04409700632095337, R-squared: 0.0071946519310081\n",
      "Epoch 125000: Loss: 0.03186405450105667, R-squared: 0.26292996381341605\n",
      "Epoch 126000: Loss: 0.39833712577819824, R-squared: -5.725834706711986\n",
      "Epoch 127000: Loss: 0.02788219414651394, R-squared: 0.3454243592726225\n",
      "Epoch 128000: Loss: 0.05374062433838844, R-squared: -0.15127260142598664\n",
      "Epoch 129000: Loss: 0.14166893064975739, R-squared: -1.9894953339699506\n",
      "Epoch 130000: Loss: 0.06498989462852478, R-squared: -0.32698616098896616\n",
      "Epoch 131000: Loss: 0.041952915489673615, R-squared: 0.12487444097053824\n",
      "Epoch 132000: Loss: 0.023936958983540535, R-squared: 0.42748349812468034\n",
      "Epoch 133000: Loss: 0.021156325936317444, R-squared: 0.5072644646695565\n",
      "Epoch 134000: Loss: 0.25612789392471313, R-squared: -4.002552552357218\n",
      "Epoch 135000: Loss: 0.03159608691930771, R-squared: 0.3636313949037616\n",
      "Epoch 136000: Loss: 0.04929265007376671, R-squared: -0.042281198568759004\n",
      "Epoch 137000: Loss: 0.07686156779527664, R-squared: -0.5557813867079213\n",
      "Epoch 138000: Loss: 0.019824182614684105, R-squared: 0.5171401615714879\n",
      "Epoch 139000: Loss: 0.8315982222557068, R-squared: -10.85634609429305\n",
      "Epoch 140000: Loss: 0.13068215548992157, R-squared: -1.3885644677313822\n",
      "Epoch 141000: Loss: 0.024251975119113922, R-squared: 0.44710318885009326\n",
      "Epoch 142000: Loss: 0.09021978080272675, R-squared: -0.7705457365846757\n",
      "Epoch 143000: Loss: 0.2176618129014969, R-squared: -1.904550273046365\n",
      "Epoch 144000: Loss: 0.04444413259625435, R-squared: 0.05596456958292939\n",
      "Epoch 145000: Loss: 0.33999064564704895, R-squared: -2.3988527582003174\n",
      "Epoch 146000: Loss: 0.053847942501306534, R-squared: 0.01828128511438376\n",
      "Epoch 147000: Loss: 0.02991492487490177, R-squared: 0.30563725842387424\n",
      "Epoch 148000: Loss: 0.04886171594262123, R-squared: 0.2869697651805332\n",
      "Epoch 149000: Loss: 0.05478786304593086, R-squared: -0.12010726649028958\n",
      "Epoch 150000: Loss: 0.020981118083000183, R-squared: 0.4909345388774391\n",
      "Epoch 151000: Loss: 0.4858037233352661, R-squared: -6.497902849173669\n",
      "Epoch 152000: Loss: 0.03263594210147858, R-squared: 0.25288488711691715\n",
      "Epoch 153000: Loss: 0.08714519441127777, R-squared: -1.2901598535392043\n",
      "Epoch 154000: Loss: 0.02467377297580242, R-squared: 0.43372889025164285\n",
      "Epoch 155000: Loss: 0.03034692071378231, R-squared: 0.4120240746448922\n",
      "Epoch 156000: Loss: 0.26870429515838623, R-squared: -4.792525341650528\n",
      "Epoch 157000: Loss: 0.04025506228208542, R-squared: 0.1246238859290194\n",
      "Epoch 158000: Loss: 0.3422043025493622, R-squared: -6.321286469183784\n",
      "Epoch 159000: Loss: 0.06307598948478699, R-squared: -0.3208034118369736\n",
      "Epoch 160000: Loss: 0.036028120666742325, R-squared: 0.24335029676106246\n",
      "Epoch 161000: Loss: 0.10577079653739929, R-squared: -0.8452401847102959\n",
      "Epoch 162000: Loss: 0.026635538786649704, R-squared: 0.41525012792232874\n",
      "Epoch 163000: Loss: 0.044656433165073395, R-squared: -0.04223756660638256\n",
      "Epoch 164000: Loss: 0.03759326785802841, R-squared: 0.1801329641717231\n",
      "Epoch 165000: Loss: 0.03990546986460686, R-squared: 0.39136320849897355\n",
      "Epoch 166000: Loss: 0.052473925054073334, R-squared: -0.006471684750320117\n",
      "Epoch 167000: Loss: 0.027503540739417076, R-squared: 0.4311500646880194\n",
      "Epoch 168000: Loss: 0.040861405432224274, R-squared: 0.07056136568967586\n",
      "Epoch 169000: Loss: 0.030061274766921997, R-squared: 0.3438307675858323\n",
      "Epoch 170000: Loss: 0.029836229979991913, R-squared: 0.29003112923837426\n",
      "Epoch 171000: Loss: 0.03295687958598137, R-squared: 0.020311313004945375\n",
      "Epoch 172000: Loss: 0.08075404167175293, R-squared: -0.40580352604624603\n",
      "Epoch 173000: Loss: 0.02626786194741726, R-squared: 0.4169221635824041\n",
      "Epoch 174000: Loss: 1.6265524625778198, R-squared: -24.676569469593534\n",
      "Epoch 175000: Loss: 0.03460298851132393, R-squared: 0.25523521584005726\n",
      "Epoch 176000: Loss: 0.08255503326654434, R-squared: -0.8370407214434517\n",
      "Epoch 177000: Loss: 0.04821097105741501, R-squared: 0.15791829412759195\n",
      "Epoch 178000: Loss: 0.03463202714920044, R-squared: 0.23762284004519996\n",
      "Epoch 179000: Loss: 0.03652159869670868, R-squared: 0.1752606775422133\n",
      "Epoch 180000: Loss: 0.09488331526517868, R-squared: -0.9190118558655178\n",
      "Epoch 181000: Loss: 0.05664493143558502, R-squared: -0.16402858723730374\n",
      "Epoch 182000: Loss: 0.08323364704847336, R-squared: -0.6656894795749777\n",
      "Epoch 183000: Loss: 0.05899329483509064, R-squared: -0.04641325595079682\n",
      "Epoch 184000: Loss: 0.021894073113799095, R-squared: 0.5850548354916247\n",
      "Epoch 185000: Loss: 0.033004965633153915, R-squared: 0.17968551804160204\n",
      "Epoch 186000: Loss: 0.0759054496884346, R-squared: -0.45569225847934414\n",
      "Epoch 187000: Loss: 0.03873883932828903, R-squared: 0.09498725656294693\n",
      "Epoch 188000: Loss: 0.12069838494062424, R-squared: -1.0911278519225363\n",
      "Epoch 189000: Loss: 0.04430457577109337, R-squared: 0.11766106020519562\n",
      "Epoch 190000: Loss: 0.028742073103785515, R-squared: 0.2972902944471598\n",
      "Epoch 191000: Loss: 0.032580312341451645, R-squared: 0.2772871265088127\n",
      "Epoch 192000: Loss: 0.04602070525288582, R-squared: 0.19463943597821398\n",
      "Epoch 193000: Loss: 0.03002585843205452, R-squared: 0.3252529331947561\n",
      "Epoch 194000: Loss: 0.11179757118225098, R-squared: -1.3754715427391297\n",
      "Epoch 195000: Loss: 0.15924645960330963, R-squared: -2.1548089436185145\n",
      "Epoch 196000: Loss: 0.14605756103992462, R-squared: -1.6367725002291653\n",
      "Epoch 197000: Loss: 0.13199718296527863, R-squared: -1.342209440829027\n",
      "Epoch 198000: Loss: 0.04437167942523956, R-squared: 0.11059055762792991\n",
      "Epoch 199000: Loss: 0.043209340423345566, R-squared: 0.2688978090969436\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=12, hidden_size=30, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(30, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _status = self.rnn(x)\n",
    "        x = self.fc(x[:, -1])\n",
    "        return x\n",
    "\n",
    "model = RNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "\n",
    "def compute_r2_score(y_true, y_pred):\n",
    "    return r2_score(y_true.detach().cpu().numpy(), y_pred.detach().cpu().numpy())\n",
    "\n",
    "for epoch in range(20000):\n",
    "    for i, (x, y) in enumerate(smp_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x.unsqueeze(1).float())\n",
    "        loss = criterion(output.squeeze(), y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        y_true = y.float().unsqueeze(1)  \n",
    "        y_pred = model(x.unsqueeze(1).float())  \n",
    "        r2 = compute_r2_score(y_true, y_pred.squeeze())\n",
    "\n",
    "        print(f\"Epoch {epoch}: Loss: {loss}, R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2835966877.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    $npm i chart.js\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
